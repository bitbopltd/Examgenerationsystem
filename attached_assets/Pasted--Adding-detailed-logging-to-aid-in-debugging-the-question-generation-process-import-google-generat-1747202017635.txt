# Adding detailed logging to aid in debugging the question generation process.
import google.generativeai as genai
import os
import random
from typing import Dict, List, Any, Optional
import time
import json
import re
import traceback

# --- Configuration ---
API_KEY = os.getenv('GEMINI_API_KEY')
if not API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable not set.")
genai.configure(api_key=API_KEY)

# --- Model and Safety Settings ---
MODEL_NAME = 'models/gemini-1.5-flash-latest' 

DEFAULT_SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
]

# --- Utility Functions ---
def log_progress(msg: str):
    """Logs a message with a timestamp and flushes the output."""
    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {msg}", flush=True)

log_progress(f"Using Gemini model: {MODEL_NAME}")
model = genai.GenerativeModel(
    MODEL_NAME,
    safety_settings=DEFAULT_SAFETY_SETTINGS
)

def extract_json_from_response(text_response: str) -> Any:
    """
    Extracts a JSON object or list from a string, handling markdown and heuristics.
    """
    if not text_response:
        log_progress("extract_json_from_response: Received empty text_response.")
        return None
    log_progress(f"extract_json_from_response: Attempting to extract JSON from: ---START RAW RESPONSE (len={len(text_response)})---\n{text_response[:1000]}{'...' if len(text_response) > 1000 else ''}\n---END RAW RESPONSE---")
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text_response, re.IGNORECASE)
    if match:
        json_str = match.group(1); log_progress("extract_json_from_response: Found JSON in markdown block.")
        try: return json.loads(json_str)
        except json.JSONDecodeError as e: log_progress(f"extract_json_from_response: Failed to decode JSON from markdown block: {e}\nProblematic: '{json_str}'"); return None
    log_progress("extract_json_from_response: No markdown JSON, trying heuristic.")
    first_b, first_sq_b = text_response.find('{'), text_response.find('[')
    start_idx = min(first_b, first_sq_b) if first_b != -1 and first_sq_b != -1 else max(first_b, first_sq_b)
    if start_idx != -1:
        cand_str = text_response[start_idx:]; ob, osb, lci = 0,0,-1
        for i,c in enumerate(cand_str):
            if c=='{':ob+=1 elif c=='}':ob-=1 elif c=='[':osb+=1 elif c==']':osb-=1
            if ob==0 and osb==0 and (c=='}' or c==']'):lci=i;break
        if lci!=-1:
            h_str=cand_str[:lci+1];log_progress(f"extract_json_from_response: Heuristic segment: '{h_str[:200]}...'")
            try: return json.loads(h_str)
            except json.JSONDecodeError as e: log_progress(f"extract_json_from_response: Failed heuristic decode: {e}\nProblematic: '{h_str}'")
        else: log_progress("extract_json_from_response: Could not find balanced end for heuristic JSON extraction.")
    else: log_progress("extract_json_from_response: No JSON start character for heuristic extraction.")
    log_progress("extract_json_from_response: Falling back to parse entire response.")
    try: return json.loads(text_response)
    except json.JSONDecodeError as e: log_progress(f"extract_json_from_response: Failed full parse: {e}"); return None

# --- Question Generation Function with API-provided Topic Summary/Keywords ---
# This function now returns (parsed_question_data, topic_summary, keywords)
def generate_single_question_with_retry(
    prompt: str,
    question_type: str,
    generation_attempt_num: int,
    excluded_topics_and_summaries: List[str], # List of summaries/keywords to avoid
    max_api_calls: int = 3
) -> tuple[Optional[Dict[str, Any]], Optional[str], List[str]]: # Returns (question_data, topic_summary, keywords)
    
    generation_config = genai.types.GenerationConfig(
        temperature=0.95, # Increased temp for max exploration
        top_p=0.95,
        max_output_tokens=2048 
    )
    modified_prompt = prompt # Start with the base prompt

    # Construct the dynamic uniqueness instruction using excluded topics/summaries
    uniqueness_header = (
        f"You are generating question number {generation_attempt_num} of type '{question_type}' for this text. "
        "It is ABSOLUTELY CRITICAL that this new question is SUBSTANTIALLY DIFFERENT in topic and focus from any previous questions you have generated for this text. "
        "DO NOT repeat themes or ask slight variations of the same core idea.\n"
    )

    if excluded_topics_and_summaries:
        uniqueness_header += "IMPORTANT: You have ALREADY generated questions covering topics or concepts related to the following: "
        # Join the list for clear presentation to the model
        uniqueness_header += f"[{'; '.join(excluded_topics_and_summaries)}].\n" 
        uniqueness_header += "Your new question MUST target COMPLETELY DIFFERENT information, details, concepts, named entities (like specific people, companies, or tools mentioned), processes, specific outcomes (like percentages or figures), relationships, or distinct sections of the provided text. "
        uniqueness_header += "EXPLICITLY AVOID any question related to the SEMANTIC AREAS covered by these previous topics. Think creatively to find a NEW, testable point or detail from the text that has not been covered.\n\n"
    else:
        uniqueness_header += "This is the first question of this type. Focus on a clear and central point from the text.\n\n"
    
    uniqueness_header += ("General guidelines for achieving diversity:\n"
                          "1. Identify a COMPLETELY NEW angle, specific detail, named entity, specific process, cause/effect relationship, comparison, or consequence mentioned in the text.\n"
                          "2. If the text is structured (e.g., multiple testimonials, paragraphs), try to draw from different structures or sections.\n"
                          "3. Vary the question phrasing and style significantly.\n\n"
                          "Now, generate the question, its guideline/options, AND provide a concise topic summary and relevant keywords as requested in the format instructions below.\n\n" 
                          "--- Original Format and Content Instructions ---\n") 

    # Combine the uniqueness header with the original prompt
    modified_prompt = uniqueness_header + prompt
    
    if generation_attempt_num > 1 or excluded_topics_and_summaries:
         log_progress(f"Prompting for {question_type} (Gen {generation_attempt_num}) with excluded topics/summaries: {excluded_topics_and_summaries if excluded_topics_and_summaries else 'None'}...")
    else:
         log_progress(f"Prompting for {question_type} (Gen {generation_attempt_num}) without exclusions...")


    for api_call_attempt in range(max_api_calls):
        try:
            log_progress(f"Sending prompt for {question_type} (Gen {generation_attempt_num}, API call {api_call_attempt + 1}/{max_api_calls})...")
            # log_progress(f"Prompt Start: {modified_prompt[:800]}...") 
            
            response = model.generate_content(modified_prompt, generation_config=generation_config)
            
            if response.prompt_feedback and response.prompt_feedback.block_reason:
                log_progress(f"Prompt blocked. Reason: {response.prompt_feedback.block_reason}. Ratings: {response.prompt_feedback.safety_ratings}")
                return None, None, [] 
            if not response.parts:
                finish_reason_msg = "Unknown"; safety_ratings_msg = "N/A"
                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if candidate.finish_reason: finish_reason_msg = candidate.finish_reason.name
                    if candidate.safety_ratings: safety_ratings_msg = str(candidate.safety_ratings)
                log_progress(f"Response has no parts. Finish: {finish_reason_msg}. Safety: {safety_ratings_msg}")
                if api_call_attempt < max_api_calls - 1: time.sleep(1 * (api_call_attempt + 1)); continue
                return None, None, []
                
            raw_text = response.text
            parsed_full_response = extract_json_from_response(raw_text)

            question_data = None
            extracted_summary = None
            extracted_keywords = []

            if parsed_full_response and isinstance(parsed_full_response, dict):
                question_data = parsed_full_response.get("question_data") # Get the nested question data
                extracted_summary = parsed_full_response.get("topic_summary") # Get the topic summary
                keywords_list = parsed_full_response.get("keywords", []) # Get the keywords list, default to empty list
                
                # Validate the nested question data
                if question_data and isinstance(question_data, dict):
                     # Basic check: ensure it's not empty and has at least a 'question' key
                     if not question_data or not question_data.get("question"):
                          log_progress(f"Extracted 'question_data' looks invalid or empty: {str(question_data)[:200]}. Setting question_data to None.")
                          question_data = None # Treat as failed if question is missing
                     else:
                         log_progress("Successfully extracted valid 'question_data' from nested JSON.")
                else:
                     log_progress(f"Could not find or 'question_data' was not a dict. Received value: {str(parsed_full_response.get('question_data'))[:200]}.")
                     question_data = None # Ensure None if not found or wrong type


                # Validate the extracted summary
                if extracted_summary and isinstance(extracted_summary, str) and len(extracted_summary.strip()) > 0:
                    log_progress(f"Successfully extracted topic summary: '{extracted_summary[:50]}...'")
                else:
                    log_progress(f"Could not find or 'topic_summary' was invalid (not string or empty). Received value: '{str(parsed_full_response.get('topic_summary'))[:200]}'. Setting summary to None.")
                    extracted_summary = None # Ensure None if invalid

                # Validate the extracted keywords
                if keywords_list and isinstance(keywords_list, list) and all(isinstance(item, str) for item in keywords_list):
                     extracted_keywords = keywords_list # Use the list if valid
                     log_progress(f"Successfully extracted '{len(extracted_keywords)}' keywords from nested JSON.")
                else:
                     log_progress(f"Extracted 'keywords' was invalid (not list of strings). Received value: {str(parsed_full_response.get('keywords'))[:200]}. Setting keywords to empty list.")
                     extracted_keywords = [] # Ensure empty list if invalid

                # Success only if we got valid question_data AND a valid topic_summary
                if question_data and extracted_summary:
                     return question_data, extracted_summary, extracted_keywords # Success!
                else:
                    # Log what was missing
                    log_progress(f"Parsed outer JSON but failed to get valid 'question_data' ({question_data is not None}) OR valid 'topic_summary' ({extracted_summary is not None}). Retrying API call...")

            else:
                # This else block means extract_json_from_response returned None or non-dict
                log_progress(f"Failed to parse outer JSON or it was not a dict on API call {api_call_attempt + 1} for {question_type} Gen {generation_attempt_num}. Retrying API call...")

            # If we reached here, parsing or extraction failed for this attempt
            if api_call_attempt < max_api_calls - 1: time.sleep(1.5 * (api_call_attempt + 1))
            else: 
                log_progress(f"Max API calls ({max_api_calls}) reached for parsing/extraction for {question_type} Gen {generation_attempt_num}. Giving up on this question.")
                return None, None, [] # Max retries for parsing/extraction

        except google.api_core.exceptions.ResourceExhausted as r_exc:
            log_progress(f"RATE LIMIT HIT ({question_type} Gen {generation_attempt_num}, API call {api_call_attempt + 1}): {str(r_exc)[:500]}")
            if api_call_attempt < max_api_calls - 1:
                delay_match = re.search(r"retry_delay {\s*seconds: (\d+)\s*}", str(r_exc))
                sleep_for = 5 
                if delay_match:
                    try: sleep_for = int(delay_match.group(1)) + 1; log_progress(f"API suggested retry_delay of {sleep_for-1}s. Sleeping for {sleep_for}s...")
                    except ValueError: log_progress(f"Could not parse retry_delay. Using default backoff."); sleep_for = (2 ** api_call_attempt) * 2 
                else: log_progress(f"No specific retry_delay. Using default backoff."); sleep_for = (2 ** api_call_attempt) * 2 
                time.sleep(sleep_for)
            else: log_progress(f"Max API calls ({max_api_calls}) due to rate limits."); return None, None, []
        except Exception as e:
            log_progress(f"CRITICAL ERROR ({question_type} Gen {generation_attempt_num}, API call {api_call_attempt + 1}): {type(e).__name__} - {str(e)}")
            traceback.print_exc()
            if api_call_attempt < max_api_calls - 1: time.sleep(2 ** api_call_attempt); log_progress("Retrying API call...")
            else: log_progress(f"Max API calls ({max_api_calls}) due to critical errors."); return None, None, []
            
    return None, None, [] # Should ideally not reach here

# --- Main Question Generation Logic ---
def generate_questions_from_text(text_content: str, num_mcq: int = 0, num_short_answer: int = 0, num_long_answer: int = 0, subject: str = "General", grade_level: str = "N/A") -> Dict[str, List[Any]]:
    generated_questions = {"mcq": [], "short_answer": [], "long_answer": []}
    if not text_content: log_progress("Input text_content is empty."); return generated_questions
    if len(text_content) < 50 and (num_mcq + num_short_answer + num_long_answer > 0):
        log_progress("Warning: Input text is very short. Quality may be affected.")

    # Initialize list of excluded topics/summaries for each type
    mcq_excluded: List[str] = []
    saq_excluded: List[str] = []
    laq_excluded: List[str] = []
    # Optional: Share excluded topics between question types if topics are highly overlapping
    # all_excluded: List[str] = [] # Uncomment if you want to pool exclusions

    # --- Generate MCQs ---
    if num_mcq > 0:
        log_progress(f"Starting MCQ generation for {num_mcq} questions...")
        # Prompt updated to request nested JSON with topic_summary and keywords
        mcq_base_prompt = f"""You are an expert quiz generator. Your primary goal is to create DIVERSE questions.
When asked to generate multiple questions from the same text, EACH new question MUST explore a different facet, detail, or concept from the text. Avoid thematic repetition.
Generate exactly ONE multiple choice question with 4 unique options based on the provided text.
In addition to the question, provide a CONCISE (3-10 words) summary of the question's core topic and 5-7 general keywords from the text that BEST represent the topic.

The response MUST be a single JSON object with exactly THREE keys:
1. "question_data": Contains a JSON object for the question in THIS exact format:
   {{
     "question": "Your question here?",
     "options": ["Option A", "Option B", "Option C", "Option D"],
     "correct_option_index": 0
   }}
   Ensure 'correct_option_index' is a 0-indexed integer. Options should be distinct and plausible.
2. "topic_summary": A CONCISE (3-10 words) string summarizing the question's core topic.
3. "keywords": A JSON list of 5-7 general keywords identifying the question's topic. Avoid stopwords and overly generic words.

Example of the full response format:
{{
  "question_data": {{ "question": "Example question?", "options": ["A", "B", "C", "D"], "correct_option_index": 1 }},
  "topic_summary": "Example topic summary.",
  "keywords": ["example", "topic", "keywords", "list"]
}}

Do NOT include any text, explanation, or apologies before or after this JSON object.
If you absolutely cannot generate a valid and *distinct* question (and corresponding data/summary) in the specified JSON format from this text, respond with ONLY this exact JSON object and nothing else: {{"question_data": {{"question": "", "options": [], "correct_option_index": -1}}, "topic_summary": "", "keywords": []}}

Text: {text_content[:4000]}"""
        
        for i in range(num_mcq):
            # Pass the current list of excluded topics/summaries to the generator
            mcq_data, extracted_summary, extracted_keywords = generate_single_question_with_retry(
                mcq_base_prompt, "MCQ", i + 1, list(set(mcq_excluded)) # Pass unique excluded items
                # If pooling: list(set(all_excluded))
            )
            
            if mcq_data and extracted_summary: # Success requires both valid question data AND a summary
                # Process question_data (same as before)
                question_text = mcq_data.get("question", "")
                try: 
                    correct_answer_text_val = mcq_data['options'][mcq_data['correct_option_index']]
                except (IndexError, TypeError):
                    log_progress(f"Error: MCQ {i+1} correct_idx {mcq_data.get('correct_option_index')} out of bounds/invalid type for options {mcq_data.get('options')}. Skipping adding to results."); continue
                shuffled_options = list(mcq_data['options']); random.shuffle(shuffled_options)
                try: 
                    new_correct_index = shuffled_options.index(correct_answer_text_val)
                except ValueError: 
                    log_progress(f"Error: MCQ {i+1} Correct ans '{correct_answer_text_val}' not found in shuffled options {shuffled_options}. Original: {mcq_data}. Skipping adding to results."); continue
                
                generated_questions["mcq"].append({"type": "mcq", "question": question_text, "options": shuffled_options, "correct_option_index": new_correct_index, "marks": 1})
                log_progress(f"Successfully generated and processed MCQ {i+1}: {question_text[:80]}...")
                
                # Add the summary and keywords provided by the API to the exclusion list for the NEXT question
                mcq_excluded.append(extracted_summary)
                if extracted_keywords: mcq_excluded.extend(extracted_keywords)
                # If pooling: all_excluded.append(extracted_summary); if extracted_keywords: all_excluded.extend(extracted_keywords)

                log_progress(f"MCQ {i+1}: Added summary '{extracted_summary}' and keywords {extracted_keywords} to exclusion list. Total unique excluded items for MCQs: {len(list(set(mcq_excluded)))}")

            else: 
                # log_progress handles specific failure reasons (parse, empty parts, invalid data, missing summary)
                log_progress(f"Failed to generate or parse valid MCQ {i+1} (missing data or summary). Skipping.")

        log_progress(f"Finished MCQ generation. Got {len(generated_questions['mcq'])} MCQs.")

    # --- Generate Short Answer Questions (Apply similar exclusion logic) ---
    if num_short_answer > 0:
        log_progress(f"Starting SAQ generation for {num_short_answer} questions...")
        # Prompt updated to request nested JSON with topic_summary and keywords
        saq_base_prompt_text = """You are an expert quiz generator for """ + subject + """ at grade """ + grade_level + """.
Generate ONE short answer question based on the provided text.
In addition to the question, provide a CONCISE (3-10 words) summary of the question's core topic and 5-7 general keywords from the text that BEST represent the topic.

The response MUST be a single JSON object with exactly THREE keys:
1. "question_data": Contains a JSON object for the question in THIS exact format:
   { "question": "Your question here?", "guideline": "Guideline for answering here." }
2. "topic_summary": A CONCISE (3-10 words) string summarizing the question's core topic.
3. "keywords": A JSON list of 5-7 general keywords identifying the question's topic. Avoid stopwords and overly generic words.

Example of the full response format:
{
  "question_data": { "question": "Example question?", "guideline": "Example guideline." },
  "topic_summary": "Example topic summary.",
  "keywords": ["example", "topic", "keywords", "list"]
}

Do NOT include any text, explanation, or apologies before or after this JSON object.
If you absolutely cannot generate a valid and *distinct* question (and corresponding data/summary) in the specified JSON format from this text, respond with ONLY: {{"question_data": {{"question": "", "guideline": ""}}, "topic_summary": "", "keywords": []}}

Text content: {text_content}"""
        for i in range(num_short_answer):
            saq_data, extracted_summary, extracted_keywords = generate_single_question_with_retry(
                saq_base_prompt_text.format(text_content=text_content[:4500]), # Format text here
                "Short Answer", i + 1, list(set(saq_excluded))
                # If pooling: list(set(all_excluded))
            )
            if saq_data and extracted_summary: # Success requires both valid question data AND a summary
                question_text = saq_data.get("question", "")
                generated_questions["short_answer"].append({"type": "short_answer", "question": question_text, "answer_guideline": saq_data['guideline'], "marks": 4})
                log_progress(f"Successfully generated and processed SAQ {i+1}: {question_text[:80]}...")
                saq_excluded.append(extracted_summary)
                if extracted_keywords: saq_excluded.extend(extracted_keywords)
                # If pooling: all_excluded.append(extracted_summary); if extracted_keywords: all_excluded.extend(extracted_keywords)
                log_progress(f"SAQ {i+1}: Added summary '{extracted_summary}' and keywords {extracted_keywords}. Total unique excluded items for SAQs: {len(list(set(saq_excluded)))}")
            else: log_progress(f"Failed to generate valid SAQ {i+1} (missing data or summary). Skipping.")
        log_progress(f"Finished SAQ generation. Got {len(generated_questions['short_answer'])} SAQs.")

    # --- Generate Long Answer Questions (Apply similar exclusion logic) ---
    if num_long_answer > 0:
        log_progress(f"Starting LAQ generation for {num_long_answer} questions...")
        # Prompt updated to request nested JSON with topic_summary and keywords
        laq_base_prompt_text = """You are an expert quiz generator for """ + subject + """ at grade """ + grade_level + """.
Generate ONE detailed essay or long answer question based on the provided text.
In addition to the question, provide a CONCISE (3-10 words) summary of the question's core topic and 5-7 general keywords from the text that BEST represent the topic.

The response MUST be a single JSON object with exactly THREE keys:
1. "question_data": Contains a JSON object for the question in THIS exact format:
   { "question": "Your essay question here?", "guideline": "Comprehensive answer guideline here." }
2. "topic_summary": A CONCISE (3-10 words) string summarizing the question's core topic.
3. "keywords": A JSON list of 5-7 general keywords identifying the question's topic. Avoid stopwords and overly generic words.

Example of the full response format:
{
  "question_data": { "question": "Example essay question?", "guideline": "Example guideline." },
  "topic_summary": "Example topic summary.",
  "keywords": ["example", "essay", "topic", "keywords", "list"]
}

Do NOT include any text, explanation, or apologies before or after this JSON object.
If you absolutely cannot generate a valid and *distinct* question (and corresponding data/summary), respond with ONLY: {{"question_data": {{"question": "", "guideline": ""}}, "topic_summary": "", "keywords": []}}

Text content: {text_content}"""
        for i in range(num_long_answer):
            laq_data, extracted_summary, extracted_keywords = generate_single_question_with_retry(
                 laq_base_prompt_text.format(text_content=text_content[:7000]), # Format text here
                 "Long Answer", i + 1, list(set(laq_excluded))
                 # If pooling: list(set(all_excluded))
            )
            if laq_data and extracted_summary: # Success requires both valid question data AND a summary
                question_text = laq_data.get("question", "")
                generated_questions["long_answer"].append({"type": "long_answer", "question": question_text, "answer_guideline": laq_data['guideline'], "marks": 8})
                log_progress(f"Successfully generated and processed LAQ {i+1}: {question_text[:80]}...")
                laq_excluded.append(extracted_summary)
                if extracted_keywords: laq_excluded.extend(extracted_keywords)
                # If pooling: all_excluded.append(extracted_summary); if extracted_keywords: all_excluded.extend(extracted_keywords)
                log_progress(f"LAQ {i+1}: Added summary '{extracted_summary}' and keywords {extracted_keywords}. Total unique excluded items for LAQs: {len(list(set(laq_excluded)))}")
            else: log_progress(f"Failed to generate valid LAQ {i+1} (missing data or summary). Skipping.")
        log_progress(f"Finished LAQ generation. Got {len(generated_questions['long_answer'])} LAQs.")
    
    # You could optionally pool all excluded summaries/keywords if you want questions of one type
    # to avoid topics covered in other types. If pooling, uncomment the `all_excluded` list
    # and use it when calling `generate_single_question_with_retry`.

    return generated_questions

# --- Example Usage ---
if __name__ == '__main__':
    # Using the richer text example
    dummy_text_rich = """
    The book "Traction" by Gino Wickman introduces the Entrepreneurial Operating System (EOS), 
    a holistic model for entrepreneurial companies to achieve traction in their business. 
    EOS focuses on Six Key Components: Vision, People, Data, Issues, Process, and Traction.

    Under the Vision component, companies define their Core Values, Purpose, Niche, and long-term goals using the Vision/Traction Organizer (V/TO). 
    The People component emphasizes having the "Right People" in the "Right Seats" using tools like the People Analyzer and Accountability Chart. 
    The Data component involves identifying key Measurables and using Scorecards to track performance weekly. 
    The Issues component focuses on identifying, discussing, and solving issues effectively, often through structured meetings like Level 10 Meetings. 
    The Process component involves documenting core processes to ensure consistency and scalability. 
    Finally, the Traction component brings everything together through tools like Rocks (90-day priorities) and Level 10 Meetings.

    Many testimonials highlight specific benefits. Company Alpha reported a 50% profit increase after implementing the Accountability Chart and Level 10 Meetings. 
    Beta Corp doubled revenue by focusing on Rocks and Core Values. Gamma Solutions improved their bottom line with Scorecards. 
    Delta Inc. reduced stress by using the People Analyzer. A testimonial from 'Pulse' mentioned 300% growth in three years. 'Image One' was acquired and later reacquired after using EOS.
    The author, Gino Wickman, is often praised for making complex business principles actionable, helping leaders achieve better work-life balance by running a more efficient business.
    The '36 hours of pain' concept is discussed in the book as a guideline for making difficult personnel decisions quickly when someone is in the "Wrong Seat". It emphasizes the need for swift action to prevent prolonged negative impact on the team.
    Another concept is the importance of holding effective weekly Level 10 Meetings to address issues and maintain accountability.
    """
    
    log_progress(f"--- Starting Question Generation Example (API Keywords/Summary for Exclusion) ---")
    # Request a number of questions designed to stress the diversity requirement
    questions = generate_questions_from_text(
        dummy_text_rich, 
        num_mcq=5, 
        num_short_answer=3, 
        num_long_answer=2, # Increased LAQ to test uniqueness there
        subject="Business Management",
        grade_level="Professional"
    )
    log_progress(f"--- Question Generation Complete. Displaying Results ---")
    
    print("\n--- Generated MCQs ---")
    if questions["mcq"]:
        for q_idx, q_data in enumerate(questions["mcq"]):
            print(f"\nMCQ {q_idx+1}: Q: {q_data['question']}")
            for i, opt in enumerate(q_data['options']): print(f"    {chr(65+i)}. {opt} {'(Correct)' if i == q_data['correct_option_index'] else ''}")
            print(f"  Marks: {q_data['marks']}")
    else: print("No MCQs generated or all failed.")

    print("\n--- Generated Short Answer Questions ---")
    if questions["short_answer"]:
        for q_idx, q_data in enumerate(questions["short_answer"]):
            print(f"\nSAQ {q_idx+1}: Q: {q_data['question']}")
            print(f"  Guideline: {q_data['answer_guideline']}\n  Marks: {q_data['marks']}")
    else: print("No SAQs generated or all failed.")

    print("\n--- Generated Long Answer Questions ---")
    if questions["long_answer"]:
        for q_idx, q_data in enumerate(questions["long_answer']):
            print(f"\nLAQ {q_idx+1}: Q: {q_data['question']}")
            print(f"  Guideline: {q_data['answer_guideline']}\n  Marks: {q_data['marks']}")
    else: print("No LAQs generated or all failed.")

    log_progress("--- Example Script Finished ---")