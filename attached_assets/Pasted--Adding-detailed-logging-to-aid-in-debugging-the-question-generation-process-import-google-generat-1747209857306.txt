# Adding detailed logging to aid in debugging the question generation process.
import google.generativeai as genai
import os
import random
from typing import Dict, List, Any, Optional
import time
import json
import re
import traceback

# Import specific exceptions for cleaner error handling
from google.api_core import exceptions 

# --- Configuration ---
API_KEY = os.getenv('GEMINI_API_KEY')
if not API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable not set.")
genai.configure(api_key=API_KEY)

# --- Model and Safety Settings ---
MODEL_NAME = 'models/gemini-1.5-flash-latest' 

DEFAULT_SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
]

# --- Utility Functions ---
def log_progress(msg: str):
    """Logs a message with a timestamp and flushes the output."""
    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {msg}", flush=True)

log_progress(f"Using Gemini model: {MODEL_NAME}")
model = genai.GenerativeModel(
    MODEL_NAME,
    safety_settings=DEFAULT_SAFETY_SETTINGS
)

def extract_json_from_response(text_response: str) -> Any:
    """
    Extracts a JSON object or list from a string, handling markdown and heuristics.
    """
    if not text_response:
        log_progress("extract_json_from_response: Received empty text_response.")
        return None
    # log_progress(f"extract_json_from_response: Attempting to extract JSON from: ---START RAW RESPONSE (len={len(text_response)})---\n{text_response[:1000]}{'...' if len(text_response) > 1000 else ''}\n---END RAW RESPONSE---")
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text_response, re.IGNORECASE)
    if match:
        json_str = match.group(1); log_progress("extract_json_from_response: Found JSON in markdown block.")
        try: return json.loads(json_str)
        except json.JSONDecodeError as e: log_progress(f"extract_json_from_response: Failed to decode JSON from markdown block: {e}\nProblematic: '{json_str}'"); return None
    # log_progress("extract_json_from_response: No markdown JSON, trying heuristic.")
    first_b, first_sq_b = text_response.find('{'), text_response.find('[')
    start_idx = min(first_b, first_sq_b) if first_b != -1 and first_sq_b != -1 else max(first_b, first_sq_b)
    if start_idx != -1:
        cand_str = text_response[start_idx:]; ob, osb, lci = 0,0,-1
        for i,c in enumerate(cand_str):
            if c=='{':ob+=1 elif c=='}':ob-=1 elif c=='[':osb+=1 elif c==']':osb-=1
            if ob==0 and osb==0 and (c=='}' or c==']'):lci=i;break
        if lci!=-1:
            h_str=cand_str[:lci+1];# log_progress(f"extract_json_from_response: Heuristic segment: '{h_str[:200]}...'")
            try: return json.loads(h_str)
            except json.JSONDecodeError as e: log_progress(f"extract_json_from_response: Failed heuristic decode: {e}\nProblematic: '{h_str}'")
        # else: log_progress("extract_json_from_response: Could not find balanced end for heuristic JSON extraction.")
    # else: log_progress("extract_json_from_response: No JSON start character for heuristic extraction.")
    # log_progress("extract_json_from_response: Falling back to parse entire response.")
    try: return json.loads(text_response)
    except json.JSONDecodeError as e: log_progress(f"extract_json_from_response: Failed full parse: {e}"); return None


# --- Question Generation Function with API-provided Topic Summary/Keywords ---
# This function now returns (parsed_question_data, topic_summary, keywords)
def generate_single_question_with_retry(
    prompt: str,
    question_type: str,
    generation_attempt_num: int,
    excluded_items: List[str], # List of summaries/keywords/items to avoid (pooled)
    max_api_calls: int = 3
) -> tuple[Optional[Dict[str, Any]], Optional[str], List[str]]: # Returns (question_data, topic_summary, keywords)
    
    generation_config = genai.types.GenerationConfig(
        temperature=0.9, # Slightly lower from 0.95, balance exploration with coherence
        top_p=0.95,
        max_output_tokens=2048 
    )
    modified_prompt = prompt # Start with the base prompt

    # Construct the dynamic uniqueness instruction using ALL excluded items
    uniqueness_header = (
        f"You are generating question number {generation_attempt_num} of type '{question_type}' for this text. "
        "It is ABSOLUTELY CRITICAL that this new question is SUBSTANTIALLY DIFFERENT in topic and focus from any previous questions you have generated from this text (including MCQs, SAQs, or LAQs if applicable). " # Emphasize all types
        "DO NOT repeat themes or ask slight variations of the same core idea.\n"
    )

    if excluded_items:
        uniqueness_header += "IMPORTANT: You have ALREADY generated questions covering topics or concepts related to the following items: "
        uniqueness_header += f"[{'; '.join(excluded_items)}].\n" 
        uniqueness_header += "Your new question MUST target COMPLETELY DIFFERENT information, details, concepts, named entities, processes, specific outcomes, relationships, or distinct sections of the provided text. "
        uniqueness_header += "EXPLICITLY AVOID any question related to the SEMANTIC AREAS covered by these previous items. Think creatively to find a NEW, testable point or detail from the text that has not been covered.\n\n"
    else:
        uniqueness_header += "This is the first question of its type for this text. Focus on a clear and central point from the text.\n\n" # Adjusted slightly
    
    uniqueness_header += ("General guidelines for achieving diversity across questions from this text:\n" # Adjusted label
                          "1. Identify a COMPLETELY NEW angle, specific detail, named entity (person, company, product), specific process, cause/effect relationship, comparison, or consequence mentioned in the text.\n"
                          "2. If the text is structured (e.g., multiple testimonials, paragraphs, sections), try to draw from different structures or sections.\n"
                          "3. Vary the question phrasing and style significantly.\n\n"
                          "Now, generate the question, its guideline/options, AND provide a concise topic summary and relevant keywords as requested in the format instructions below.\n\n" 
                          "--- Original Format and Content Instructions ---\n") 

    # Combine the uniqueness header with the original prompt
    modified_prompt = uniqueness_header + prompt
    
    if generation_attempt_num > 1 or excluded_items:
         log_progress(f"Prompting for {question_type} (Gen {generation_attempt_num}) with {len(list(set(excluded_items)))} unique excluded items...")
    else:
         log_progress(f"Prompting for {question_type} (Gen {generation_attempt_num}) without exclusions...")


    for api_call_attempt in range(max_api_calls):
        try:
            log_progress(f"Sending prompt for {question_type} (Gen {generation_attempt_num}, API call {api_call_attempt + 1}/{max_api_calls})...")
            # log_progress(f"Prompt Start: {modified_prompt[:800]}...") 
            
            response = model.generate_content(modified_prompt, generation_config=generation_config)
            
            if response.prompt_feedback and response.prompt_feedback.block_reason:
                log_progress(f"Prompt blocked. Reason: {response.prompt_feedback.block_reason}. Ratings: {response.prompt_feedback.safety_ratings}")
                return None, None, [] 
            if not response.parts:
                finish_reason_msg = "Unknown"; safety_ratings_msg = "N/A"
                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if candidate.finish_reason: finish_reason_msg = candidate.finish_reason.name
                    if candidate.safety_ratings: safety_ratings_msg = str(candidate.safety_ratings)
                log_progress(f"Response has no parts. Finish: {finish_reason_msg}. Safety: {safety_ratings_msg}")
                if api_call_attempt < max_api_calls - 1: time.sleep(1 * (api_call_attempt + 1)); continue
                return None, None, []
                
            raw_text = response.text
            parsed_full_response = extract_json_from_response(raw_text)

            question_data = None
            extracted_summary = None
            extracted_keywords = []

            if parsed_full_response and isinstance(parsed_full_response, dict):
                question_data = parsed_full_response.get("question_data") # Get the nested question data
                extracted_summary = parsed_full_response.get("topic_summary") # Get the topic summary
                keywords_list = parsed_full_response.get("keywords", []) # Get the keywords list, default to empty list
                
                # Validate the nested question data
                if question_data and isinstance(question_data, dict):
                     if not question_data or not question_data.get("question"):
                          log_progress(f"Extracted 'question_data' looks invalid or empty: {str(question_data)[:200]}. Setting question_data to None.")
                          question_data = None 
                     else:
                         log_progress("Successfully extracted valid 'question_data' from nested JSON.")
                else:
                     log_progress(f"Could not find or 'question_data' was not a dict. Received value: {str(parsed_full_response.get('question_data'))[:200]}.")
                     question_data = None 

                # Validate the extracted summary
                if extracted_summary and isinstance(extracted_summary, str) and len(extracted_summary.strip()) > 0:
                    extracted_summary = extracted_summary.strip() # Clean up whitespace
                    log_progress(f"Successfully extracted topic summary: '{extracted_summary[:50]}...'")
                else:
                    log_progress(f"Could not find or 'topic_summary' was invalid (not string or empty). Received value: '{str(parsed_full_response.get('topic_summary'))[:200]}'. Setting summary to None.")
                    extracted_summary = None 

                # Validate the extracted keywords
                if keywords_list and isinstance(keywords_list, list) and all(isinstance(item, str) for item in keywords_list):
                     # Clean up keywords - strip whitespace, maybe lowercase?
                     extracted_keywords = [kw.strip().lower() for kw in keywords_list if kw.strip()] # lowercase and strip
                     log_progress(f"Successfully extracted '{len(extracted_keywords)}' keywords from nested JSON.")
                else:
                     log_progress(f"Extracted 'keywords' was invalid (not list of strings). Received value: {str(parsed_full_response.get('keywords'))[:200]}. Setting keywords to empty list.")
                     extracted_keywords = [] 

                # Success only if we got valid question_data AND a valid topic_summary
                if question_data and extracted_summary:
                     return question_data, extracted_summary, extracted_keywords # Success!
                else:
                    log_progress(f"Parsed outer JSON but failed to get valid 'question_data' ({question_data is not None}) OR valid 'topic_summary' ({extracted_summary is not None}). Retrying API call...")

            else:
                log_progress(f"Failed to parse outer JSON or it was not a dict on API call {api_call_attempt + 1} for {question_type} Gen {generation_attempt_num}. Retrying API call...")

            if api_call_attempt < max_api_calls - 1: time.sleep(1.5 * (api_call_attempt + 1))
            else: 
                log_progress(f"Max API calls ({max_api_calls}) reached for parsing/extraction for {question_type} Gen {generation_attempt_num}. Giving up on this question.")
                return None, None, [] 
        
        except exceptions.ResourceExhausted as r_exc: 
            log_progress(f"RATE LIMIT HIT ({question_type} Gen {generation_attempt_num}, API call {api_call_attempt + 1}): {str(r_exc)[:500]}")
            if api_call_attempt < max_api_calls - 1:
                delay_match = re.search(r"retry_delay {\s*seconds: (\d+)\s*}", str(r_exc))
                sleep_for = 5 
                if delay_match:
                    try: sleep_for = int(delay_match.group(1)) + 1; log_progress(f"API suggested retry_delay of {sleep_for-1}s. Sleeping for {sleep_for}s...")
                    except ValueError: log_progress(f"Could not parse retry_delay from error. Using default backoff."); sleep_for = (2 ** api_call_attempt) * 2 
                else: log_progress(f"No specific retry_delay in error. Using default backoff."); sleep_for = (2 ** api_call_attempt) * 2 
                time.sleep(sleep_for)
            else: log_progress(f"Max API calls ({max_api_calls}) due to rate limits."); return None, None, []
        except Exception as e:
            log_progress(f"CRITICAL ERROR ({question_type} Gen {generation_attempt_num}, API call {api_call_attempt + 1}): {type(e).__name__} - {str(e)}")
            traceback.print_exc()
            if api_call_attempt < max_api_calls - 1: time.sleep(2 ** api_call_attempt); log_progress("Retrying API call...")
            else: log_progress(f"Max API calls ({max_api_calls}) due to critical errors."); return None, None, []
            
    return None, None, [] 

# --- Main Question Generation Logic ---
def generate_questions_from_text(text_content: str, num_mcq: int = 0, num_short_answer: int = 0, num_long_answer: int = 0, subject: str = "General", grade_level: str = "N/A") -> Dict[str, List[Any]]:
    generated_questions = {"mcq": [], "short_answer": [], "long_answer": []}
    if not text_content: log_progress("Input text_content is empty."); return generated_questions
    if len(text_content) < 50 and (num_mcq + num_short_answer + num_long_answer > 0):
        log_progress("Warning: Input text is very short. Quality may be affected.")

    # Initialize a SINGLE list of excluded items (summaries + keywords) for ALL question types
    all_excluded_items: List[str] = []

    # --- Generate MCQs ---
    if num_mcq > 0:
        log_progress(f"Starting MCQ generation for {num_mcq} questions...")
        # Prompt updated to request nested JSON with topic_summary and keywords
        mcq_base_prompt = f"""You are an expert quiz generator. Your primary goal is to create DIVERSE questions.
When asked to generate multiple questions from the same text, EACH new question MUST explore a different facet, detail, or concept from the text. Avoid thematic repetition.
Generate exactly ONE multiple choice question with 4 unique options based on the provided text.
In addition to the question, provide a CONCISE (3-10 words) summary of the question's core topic and 5-7 general keywords from the text that BEST represent the topic.

The response MUST be a single JSON object with exactly THREE keys:
1. "question_data": Contains a JSON object for the question in THIS exact format:
   {{
     "question": "Your question here?",
     "options": ["Option A", "Option B", "Option C", "Option D"],
     "correct_option_index": 0
   }}
   Ensure 'correct_option_index' is a 0-indexed integer. Options should be distinct and plausible.
2. "topic_summary": A CONCISE (3-10 words) string summarizing the question's core topic.
3. "keywords": A JSON list of 5-7 general keywords identifying the question's topic. Avoid stopwords and overly generic words.

Example of the full response format:
{{
  "question_data": {{ "question": "Example question?", "options": ["A", "B", "C", "D"], "correct_option_index": 1 }},
  "topic_summary": "Example topic summary.",
  "keywords": ["example", "topic", "keywords", "list"]
}}

Do NOT include any text, explanation, or apologies before or after this JSON object.
If you absolutely cannot generate a valid and *distinct* question (and corresponding data/summary) in the specified JSON format from this text, respond with ONLY this exact JSON object and nothing else: {{"question_data": {{"question": "", "options": [], "correct_option_index": -1}}, "topic_summary": "", "keywords": []}}

Text: {text_content[:4000]}"""
        
        for i in range(num_mcq):
            # Pass the current POOLED list of excluded items (summaries + keywords)
            excluded_for_prompt = list(set(all_excluded_items)) # Use set for unique items in prompt
            mcq_data, extracted_summary, extracted_keywords = generate_single_question_with_retry(
                mcq_base_prompt, "MCQ", i + 1, excluded_for_prompt 
            )
            
            if mcq_data and extracted_summary: # Success requires both valid question data AND a summary
                # Process question_data
                question_text = mcq_data.get("question", "")
                try: 
                    correct_answer_text_val = mcq_data['options'][mcq_data['correct_option_index']]
                except (IndexError, TypeError):
                    log_progress(f"Error: MCQ {i+1} correct_idx {mcq_data.get('correct_option_index')} out of bounds/invalid type for options {mcq_data.get('options')}. Skipping adding to results."); continue
                shuffled_options = list(mcq_data['options']); random.shuffle(shuffled_options)
                try: 
                    new_correct_index = shuffled_options.index(correct_answer_text_val)
                except ValueError: 
                    log_progress(f"Error: MCQ {i+1} Correct ans '{correct_answer_text_val}' not found in shuffled options {shuffled_options}. Original: {mcq_data}. Skipping adding to results."); continue
                
                generated_questions["mcq"].append({"type": "mcq", "question": question_text, "options": shuffled_options, "correct_option_index": new_correct_index, "marks": 1})
                log_progress(f"Successfully generated and processed MCQ {i+1}: {question_text[:80]}...")
                
                # Add the summary and keywords provided by the API to the POOLED exclusion list
                all_excluded_items.append(extracted_summary)
                if extracted_keywords: all_excluded_items.extend(extracted_keywords)

                log_progress(f"MCQ {i+1}: Added summary '{extracted_summary}' and keywords {extracted_keywords}. Total unique excluded items (pooled): {len(list(set(all_excluded_items)))}")

            else: 
                log_progress(f"Failed to generate or parse valid MCQ {i+1} (missing data or summary). Skipping.")

        log_progress(f"Finished MCQ generation. Got {len(generated_questions['mcq'])} MCQs.")

    # --- Generate Short Answer Questions (Apply POOLED exclusion logic) ---
    if num_short_answer > 0:
        log_progress(f"Starting SAQ generation for {num_short_answer} questions...")
        saq_base_prompt_text = """You are an expert quiz generator for """ + subject + """ at grade """ + grade_level + """.
Generate ONE short answer question based on the provided text.
In addition to the question, provide a CONCISE (3-10 words) summary of the question's core topic and 5-7 general keywords from the text that BEST represent the topic.

The response MUST be a single JSON object with exactly THREE keys:
1. "question_data": Contains a JSON object for the question in THIS exact format:
   { "question": "Your question here?", "guideline": "Guideline for answering here." }
2. "topic_summary": A CONCISE (3-10 words) string summarizing the question's core topic.
3. "keywords": A JSON list of 5-7 general keywords identifying the question's topic. Avoid stopwords and overly generic words.

Example of the full response format:
{
  "question_data": { "question": "Example question?", "guideline": "Example guideline." },
  "topic_summary": "Example topic summary.",
  "keywords": ["example", "topic", "keywords", "list"]
}

Do NOT include any text, explanation, or apologies before or after this JSON object.
If you absolutely cannot generate a valid and *distinct* question (and corresponding data/summary) in the specified JSON format from this text, respond with ONLY: {{"question_data": {{"question": "", "guideline": ""}}, "topic_summary": "", "keywords": []}}

Text content: {text_content}"""
        for i in range(num_short_answer):
            # Pass the current POOLED list of excluded items
            excluded_for_prompt = list(set(all_excluded_items)) 
            saq_data, extracted_summary, extracted_keywords = generate_single_question_with_retry(
                saq_base_prompt_text.format(text_content=text_content[:4500]), 
                "Short Answer", i + 1, excluded_for_prompt
            )
            if saq_data and extracted_summary:
                question_text = saq_data.get("question", "")
                generated_questions["short_answer"].append({"type": "short_answer", "question": question_text, "answer_guideline": saq_data['guideline'], "marks": 4})
                log_progress(f"Successfully generated and processed SAQ {i+1}: {question_text[:80]}...")
                all_excluded_items.append(extracted_summary)
                if extracted_keywords: all_excluded_items.extend(extracted_keywords)
                log_progress(f"SAQ {i+1}: Added summary '{extracted_summary}' and keywords {extracted_keywords}. Total unique excluded items (pooled): {len(list(set(all_excluded_items)))}")
            else: log_progress(f"Failed to generate valid SAQ {i+1} (missing data or summary). Skipping.")
        log_progress(f"Finished SAQ generation. Got {len(generated_questions['short_answer'])} SAQs.")

    # --- Generate Long Answer Questions (Apply POOLED exclusion logic) ---
    if num_long_answer > 0:
        log_progress(f"Starting LAQ generation for {num_long_answer} questions...")
        laq_base_prompt_text = """You are an expert quiz generator for """ + subject + """ at grade """ + grade_level + """.
Generate ONE detailed essay or long answer question based on the provided text.
In addition to the question, provide a CONCISE (3-10 words) summary of the question's core topic and 5-7 general keywords from the text that BEST represent the topic.

The response MUST be a single JSON object with exactly THREE keys:
1. "question_data": Contains a JSON object for the question in THIS exact format:
   { "question": "Your essay question here?", "guideline": "Comprehensive answer guideline here." }
2. "topic_summary": A CONCISE (3-10 words) string summarizing the question's core topic.
3. "keywords": A JSON list of 5-7 general keywords identifying the question's topic. Avoid stopwords and overly generic words.

Example of the full response format:
{
  "question_data": { "question": "Example essay question?", "guideline": "Example guideline." },
  "topic_summary": "Example topic summary.",
  "keywords": ["example", "essay", "topic", "keywords", "list"]
}

Do NOT include any text, explanation, or apologies before or after this JSON object.
If you absolutely cannot generate a valid and *distinct* question (and corresponding data/summary), respond with ONLY: {{"question_data": {{"question": "", "guideline": ""}}, "topic_summary": "", "keywords": []}}

Text content: {text_content}"""
        for i in range(num_long_answer):
            # Pass the current POOLED list of excluded items
            excluded_for_prompt = list(set(all_excluded_items))
            laq_data, extracted_summary, extracted_keywords = generate_single_question_with_retry(
                 laq_base_prompt_text.format(text_content=text_content[:7000]), 
                 "Long Answer", i + 1, excluded_for_prompt
            )
            if laq_data and extracted_summary:
                question_text = laq_data.get("question", "")
                generated_questions["long_answer"].append({"type": "long_answer", "question": question_text, "answer_guideline": laq_data['guideline'], "marks": 8})
                log_progress(f"Successfully generated and processed LAQ {i+1}: {question_text[:80]}...")
                all_excluded_items.append(extracted_summary)
                if extracted_keywords: all_excluded_items.extend(extracted_keywords)
                log_progress(f"LAQ {i+1}: Added summary '{extracted_summary}' and keywords {extracted_keywords}. Total unique excluded items (pooled): {len(list(set(all_excluded_items)))}")
            else: log_progress(f"Failed to generate valid LAQ {i+1} (missing data or summary). Skipping.")
        log_progress(f"Finished LAQ generation. Got {len(generated_questions['long_answer'])} LAQs.")
    
    # Optional: Return the final combined excluded items if useful for debugging or analytics
    # total_unique_excluded = list(set(all_excluded_items))
    # log_progress(f"Final total unique items excluded across all types: {len(total_unique_excluded)}")

    return generated_questions

# --- Example Usage ---
if __name__ == '__main__':
    # Using the richer text example with added details about concepts like 36 hours of pain
    dummy_text_richer = """
    The book "Traction" by Gino Wickman introduces the Entrepreneurial Operating System (EOS), 
    a holistic model for entrepreneurial companies to achieve traction in their business. 
    EOS focuses on Six Key Components: Vision, People, Data, Issues, Process, and Traction.

    Under the Vision component, companies define their Core Values, Purpose, Niche, and long-term goals using the Vision/Traction Organizer (V/TO). 
    The People component emphasizes having the "Right People" in the "Right Seats" using tools like the People Analyzer and Accountability Chart. 
    The Data component involves identifying key Measurables and using Scorecards to track performance weekly. 
    The Issues component focuses on identifying, discussing, and solving issues effectively, often through structured meetings like Level 10 Meetings. 
    The Process component involves documenting core processes to ensure consistency and scalability. 
    Finally, the Traction component brings everything together through tools like Rocks (90-day priorities) and Level 10 Meetings.

    Many testimonials highlight specific benefits. Company Alpha reported a 50% profit increase after implementing the Accountability Chart and Level 10 Meetings. 
    Beta Corp doubled revenue by focusing on Rocks and Core Values. Gamma Solutions improved their bottom line with Scorecards. 
    Delta Inc. reduced stress by using the People Analyzer. A testimonial from 'Pulse' mentioned 300% growth in three years. 'Image One' was acquired and later reacquired after using EOS.
    The author, Gino Wickman, is often praised for making complex business principles actionable, helping leaders achieve better work-life balance by running a more efficient business.
    The '36 hours of pain' concept is discussed in the book as a guideline for making difficult personnel decisions quickly when someone is in the "Wrong Seat". It emphasizes the need for swift action to prevent prolonged negative impact on the team.
    Another concept is the importance of holding effective weekly Level 10 Meetings to address issues and maintain accountability.
    Rob Dube, President of Image One, is a key figure mentioned for his company's journey through sale and reacquisition after implementing EOS, highlighting the system's ability to build durable businesses.
    Dan Sullivan, President and Founder of The Strategic Coach, provides a testimonial mentioning he has coached and trained over 13,000 entrepreneurs, endorsing the effectiveness of Traction's principles.
    The book also describes the three major functions of any business: Sales & Marketing, Operations, and Finance. It highlights five common frustrations entrepreneurs face: lack of control, people issues, profit concerns, insufficient growth, and "hitting the ceiling". It mentions a Yiddish word, "Schlemiel," for a visionary who can't execute.
    """
    
    log_progress(f"--- Starting Question Generation Example (Pooled Exclusion) ---")
    questions = generate_questions_from_text(
        dummy_text_richer, # Using the even richer text
        num_mcq=5, 
        num_short_answer=3, 
        num_long_answer=3, # Request 3 LAQs to test diversity further
        subject="Business Management",
        grade_level="Professional"
    )
    log_progress(f"--- Question Generation Complete. Displaying Results ---")
    
    print("\n--- Generated MCQs ---")
    if questions["mcq"]:
        for q_idx, q_data in enumerate(questions["mcq"]):
            print(f"\nMCQ {q_idx+1}: Q: {q_data['question']}")
            for i, opt in enumerate(q_data['options']): print(f"    {chr(65+i)}. {opt} {'(Correct)' if i == q_data['correct_option_index'] else ''}")
            print(f"  Marks: {q_data['marks']}")
    else: print("No MCQs generated or all failed.")

    print("\n--- Generated Short Answer Questions ---")
    if questions["short_answer"]:
        for q_idx, q_data in enumerate(questions["short_answer"]):
            print(f"\nSAQ {q_idx+1}: Q: {q_data['question']}")
            print(f"  Guideline: {q_data['answer_guideline']}\n  Marks: {q_data['marks']}")
    else: print("No SAQs generated or all failed.")

    print("\n--- Generated Long Answer Questions ---")
    if questions["long_answer"]:
        for q_idx, q_data in enumerate(questions["long_answer"]):
            print(f"\nLAQ {q_idx+1}: Q: {q_data['question']}")
            print(f"  Guideline: {q_data['answer_guideline']}\n  Marks: {q_data['marks']}")
    else: print("No LAQs generated or all failed.")

    log_progress("--- Example Script Finished ---")