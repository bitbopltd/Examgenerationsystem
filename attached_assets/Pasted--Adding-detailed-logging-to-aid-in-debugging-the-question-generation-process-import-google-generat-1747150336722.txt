# Adding detailed logging to aid in debugging the question generation process.
import google.generativeai as genai
import os
import random
from typing import Dict, List, Any
import time
import json
import re # For regular expressions

# --- Configuration ---
# Ensure your GEMINI_API_KEY environment variable is set correctly
API_KEY = os.getenv('GEMINI_API_KEY')
if not API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable not set.")
genai.configure(api_key=API_KEY)

# --- Model and Safety Settings ---
# Using Gemini 1.5 Flash - optimized for speed and cost.
MODEL_NAME = 'models/gemini-1.5-flash-latest'

DEFAULT_SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
]

# --- Utility Functions ---
def log_progress(msg: str):
    """Logs a message with a timestamp and flushes the output."""
    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {msg}", flush=True)

log_progress(f"Using Gemini model: {MODEL_NAME}")
model = genai.GenerativeModel(
    MODEL_NAME,
    safety_settings=DEFAULT_SAFETY_SETTINGS
)

def extract_json_from_response(text_response: str) -> Any:
    """
    Extracts a JSON object or list from a string,
    handling potential markdown code blocks and attempting heuristic extraction.
    """
    if not text_response:
        log_progress("extract_json_from_response: Received empty text_response.")
        return None

    # Log the full response for debugging. Truncate in production if responses are huge.
    log_progress(f"extract_json_from_response: Attempting to extract JSON from: ---START RAW RESPONSE (len={len(text_response)})---\n{text_response[:1000]}{'...' if len(text_response) > 1000 else ''}\n---END RAW RESPONSE---")

    # 1. Try to find JSON within markdown triple backticks
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text_response, re.IGNORECASE)
    if match:
        json_str = match.group(1)
        log_progress("extract_json_from_response: Found JSON in markdown block.")
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            log_progress(f"extract_json_from_response: Failed to decode JSON from markdown block: {e}")
            log_progress(f"Problematic JSON string (from markdown): '{json_str}'")
            return None # Malformed JSON within markdown is an error here

    # 2. If no markdown, try to find the first '{' or '[' and use heuristic balancing
    log_progress("extract_json_from_response: No markdown JSON found, trying heuristic extraction.")
    first_brace = text_response.find('{')
    first_bracket = text_response.find('[')
    
    start_index = -1
    if first_brace != -1 and (first_bracket == -1 or first_brace < first_bracket):
        start_index = first_brace
    elif first_bracket != -1:
        start_index = first_bracket

    if start_index != -1:
        json_candidate_str = text_response[start_index:]
        log_progress(f"extract_json_from_response: Potential JSON start. Candidate (from index {start_index}): '{json_candidate_str[:300]}...'")
        
        open_braces = 0
        open_brackets = 0
        last_char_index = -1
        for i, char in enumerate(json_candidate_str):
            if char == '{': open_braces += 1
            elif char == '}': open_braces -= 1
            elif char == '[': open_brackets += 1
            elif char == ']': open_brackets -= 1
            if open_braces == 0 and open_brackets == 0 and (char == '}' or char == ']'):
                last_char_index = i
                break
        
        if last_char_index != -1:
            json_str_heuristic = json_candidate_str[:last_char_index+1]
            log_progress(f"extract_json_from_response: Heuristically extracted segment: '{json_str_heuristic[:500]}...'")
            try:
                return json.loads(json_str_heuristic)
            except json.JSONDecodeError as e:
                log_progress(f"extract_json_from_response: Failed to decode heuristically extracted JSON: {e}")
                log_progress(f"Problematic JSON string (heuristic): '{json_str_heuristic}'")
                # Fall through if heuristic fails
        else:
            log_progress("extract_json_from_response: Could not find balanced end for heuristic JSON extraction.")
    else:
        log_progress("extract_json_from_response: No JSON start character for heuristic extraction.")

    # 3. As a last resort, try to parse the entire original response string.
    log_progress("extract_json_from_response: Falling back to parsing the entire original response string.")
    try:
        return json.loads(text_response)
    except json.JSONDecodeError as e:
        log_progress(f"extract_json_from_response: Failed to decode JSON from the entire original response: {e}")
        return None

def generate_single_question_with_retry(prompt: str, question_type: str, generation_attempt_num: int, max_api_calls: int = 3) -> Any:
    """
    Sends a prompt to Gemini API, attempts to parse JSON, and retries.
    Includes generation_config and prompt modification for variety.
    """
    generation_config = genai.types.GenerationConfig(
        temperature=0.7, # Flash models can sometimes benefit from slightly lower temperatures for structured output
        top_p=0.95,
        # top_k=40, # Often not needed if top_p is used
        max_output_tokens=2048 # Gemini 1.5 Flash supports larger outputs, good for detailed guidelines
    )

    modified_prompt = prompt
    if generation_attempt_num > 1: # If asking for 2nd, 3rd, etc., question of this type
        modified_prompt = (
            "Please generate a NEW and DISTINCT question based on the following instructions and text. "
            "Focus on different aspects or details than any previous questions for this text.\n\n"
            + prompt
        )
        log_progress(f"Modified prompt for uniqueness for {question_type} (Overall attempt {generation_attempt_num}).")

    for api_call_attempt in range(max_api_calls):
        try:
            log_progress(f"Sending prompt for {question_type} (Gen attempt {generation_attempt_num}, API call {api_call_attempt + 1}/{max_api_calls})...")
            
            response = model.generate_content(
                modified_prompt,
                generation_config=generation_config,
                # safety_settings are applied at model level
            )

            if response.prompt_feedback and response.prompt_feedback.block_reason:
                log_progress(f"Prompt blocked by API. Reason: {response.prompt_feedback.block_reason}")
                if response.prompt_feedback.safety_ratings:
                    log_progress(f"  Safety Ratings: {response.prompt_feedback.safety_ratings}")
                return None 

            if not response.parts:
                finish_reason_msg = "Unknown"
                safety_ratings_msg = "N/A"
                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if candidate.finish_reason:
                        finish_reason_msg = candidate.finish_reason.name
                    if candidate.safety_ratings:
                        safety_ratings_msg = str(candidate.safety_ratings)
                log_progress(f"Response has no parts (text). Finish reason: {finish_reason_msg}. Safety ratings: {safety_ratings_msg}")
                if api_call_attempt < max_api_calls - 1: 
                    time.sleep(1 * (api_call_attempt + 1)) 
                    continue 
                return None 

            raw_text = response.text
            log_progress(f"Received response from Gemini API. Raw text length: {len(raw_text)} chars.")
            
            parsed_data = extract_json_from_response(raw_text)
            if parsed_data:
                log_progress("Successfully parsed JSON from response.")
                return parsed_data
            else:
                log_progress(f"Failed to parse JSON from response on API call {api_call_attempt + 1} for {question_type} Gen {generation_attempt_num}.")
                if api_call_attempt < max_api_calls - 1:
                    log_progress("Retrying API call after JSON parsing failure...")
                    time.sleep(1.5 * (api_call_attempt + 1)) 
                else:
                    log_progress(f"Max API call retries ({max_api_calls}) reached for parsing JSON for {question_type} Gen {generation_attempt_num}.")
                    return None
        
        except Exception as e:
            log_progress(f"CRITICAL ERROR during API call/processing ({question_type} Gen {generation_attempt_num}, API call {api_call_attempt + 1}): {type(e).__name__} - {str(e)}")
            import traceback
            traceback.print_exc() 
            if api_call_attempt < max_api_calls - 1:
                log_progress("Retrying API call due to critical error...")
                time.sleep(2 ** api_call_attempt) 
            else:
                log_progress(f"Max API call retries ({max_api_calls}) reached due to critical errors for {question_type} Gen {generation_attempt_num}.")
                return None
    return None 

# --- Main Question Generation Logic ---
def generate_questions_from_text(text_content: str, num_mcq: int = 0, num_short_answer: int = 0, num_long_answer: int = 0, subject: str = "General", grade_level: str = "N/A") -> Dict[str, List[Any]]:
    generated_questions = {
        "mcq": [],
        "short_answer": [],
        "long_answer": []
    }

    if not text_content:
        log_progress("Input text_content is empty. Returning empty questions.")
        return generated_questions
    
    if len(text_content) < 50 and (num_mcq + num_short_answer + num_long_answer > 0): 
        log_progress("Warning: Input text content is very short. Question quality might be severely affected or generation might fail.")

    # --- Generate MCQs ---
    if num_mcq > 0:
        log_progress(f"Starting MCQ generation for {num_mcq} questions...")
        # For Gemini 1.5 Flash, we can be a bit more generous with context if needed, but 2500 is a good start.
        mcq_base_prompt = f"""You are an expert quiz generator.
Generate exactly ONE multiple choice question with 4 unique options based on the provided text.
The response MUST be a single JSON object in this exact format:
{{
  "question": "Your question here?",
  "options": ["Option A", "Option B", "Option C", "Option D"],
  "correct_option_index": 0
}}
Ensure 'correct_option_index' is a 0-indexed integer referring to the correct option.
Options should be distinct and plausible.
Do NOT include any text, explanation, or apologies before or after the JSON object.
If you absolutely cannot generate a valid question in the specified JSON format from this text, respond with ONLY this exact JSON object and nothing else: {{"question": "", "options": [], "correct_option_index": -1}}

Text: {text_content[:3000]}""" # Slightly increased context for Flash

        for i in range(num_mcq):
            mcq_data = generate_single_question_with_retry(mcq_base_prompt, "MCQ", i + 1)

            if mcq_data and isinstance(mcq_data, dict) and \
               mcq_data.get("question") is not None and \
               mcq_data.get("options") is not None and \
               mcq_data.get("correct_option_index") is not None:
                
                if mcq_data["question"] == "" and mcq_data["options"] == [] and mcq_data["correct_option_index"] == -1:
                    log_progress(f"MCQ {i+1}: Model indicated failure to generate. Skipping.")
                    continue
                
                if not isinstance(mcq_data["options"], list) or len(mcq_data["options"]) != 4 or \
                   not isinstance(mcq_data["correct_option_index"], int):
                    log_progress(f"MCQ {i+1}: Invalid structure after parsing. Data: {str(mcq_data)[:300]}. Skipping.")
                    continue

                try:
                    correct_answer_text = mcq_data['options'][mcq_data['correct_option_index']]
                except IndexError:
                    log_progress(f"Error: MCQ {i+1} correct_option_index {mcq_data['correct_option_index']} out of bounds for options {mcq_data['options']}. Skipping.")
                    continue
                
                shuffled_options = list(mcq_data['options']) 
                random.shuffle(shuffled_options)
                try:
                    new_correct_index = shuffled_options.index(correct_answer_text)
                except ValueError:
                    log_progress(f"Error: MCQ {i+1} Original correct answer '{correct_answer_text}' not found in shuffled options {shuffled_options}. Original: {mcq_data}. Skipping.")
                    continue
                
                generated_questions["mcq"].append({
                    "type": "mcq",
                    "question": mcq_data['question'],
                    "options": shuffled_options,
                    "correct_option_index": new_correct_index,
                    "marks": 1
                })
                log_progress(f"Successfully generated and processed MCQ {i+1}.")
            else:
                log_progress(f"Failed to generate valid MCQ {i+1} (data missing or not dict). Received: {str(mcq_data)[:300]}...")
        log_progress(f"Finished MCQ generation. Got {len(generated_questions['mcq'])} MCQs.")

    # --- Generate Short Answer Questions ---
    if num_short_answer > 0:
        log_progress(f"Starting Short Answer Question generation for {num_short_answer} questions...")
        saq_base_prompt_template = f"""You are an expert quiz generator for {subject} at grade {grade_level}.
Based on the provided text, generate exactly ONE short answer question.
For the question, provide:
- The question text
- A guideline for answering (key points to cover or expected answer elements)
The response MUST be a single JSON object in this exact format:
{{
  "question": "Your question here?",
  "guideline": "Guideline for answering here."
}}
Do NOT include any text, explanation, or apologies before or after the JSON object.
If you absolutely cannot generate a valid question in the specified JSON format from this text, respond with ONLY this exact JSON object and nothing else: {{"question": "", "guideline": ""}}

Text content: {{text_content}}"""
        for i in range(num_short_answer):
            current_prompt = saq_base_prompt_template.format(text_content=text_content[:4000]) # Increased context for Flash
            saq_data = generate_single_question_with_retry(current_prompt, "Short Answer", i + 1)

            if saq_data and isinstance(saq_data, dict) and \
               saq_data.get("question") is not None and saq_data.get("guideline") is not None:
                if saq_data["question"] == "" and saq_data["guideline"] == "":
                    log_progress(f"SAQ {i+1}: Model indicated failure to generate. Skipping.")
                    continue
                generated_questions["short_answer"].append({
                    "type": "short_answer",
                    "question": saq_data['question'],
                    "answer_guideline": saq_data['guideline'],
                    "marks": 4
                })
                log_progress(f"Successfully generated and processed Short Answer Question {i+1}.")
            else:
                log_progress(f"Failed to generate valid SAQ {i+1} (data missing or not dict). Received: {str(saq_data)[:300]}...")
        log_progress(f"Finished SAQ generation. Got {len(generated_questions['short_answer'])} SAQs.")

    # --- Generate Long Answer Questions ---
    if num_long_answer > 0:
        log_progress(f"Starting Long Answer Question generation for {num_long_answer} questions...")
        laq_base_prompt_template = f"""You are an expert quiz generator for {subject} at grade {grade_level}.
Based on the provided text, generate exactly ONE detailed essay or long answer question.
For the question, provide:
- The question text
- A comprehensive answer guideline outlining key concepts, arguments, or points to be included.
The response MUST be a single JSON object in this exact format:
{{
  "question": "Your essay question here?",
  "guideline": "Comprehensive answer guideline here."
}}
Do NOT include any text, explanation, or apologies before or after the JSON object.
If you absolutely cannot generate a valid question in the specified JSON format from this text, respond with ONLY this exact JSON object and nothing else: {{"question": "", "guideline": ""}}

Text content: {{text_content}}"""
        for i in range(num_long_answer):
            current_prompt = laq_base_prompt_template.format(text_content=text_content[:6000]) # Increased context for Flash
            laq_data = generate_single_question_with_retry(current_prompt, "Long Answer", i + 1)

            if laq_data and isinstance(laq_data, dict) and \
               laq_data.get("question") is not None and laq_data.get("guideline") is not None:
                if laq_data["question"] == "" and laq_data["guideline"] == "":
                    log_progress(f"LAQ {i+1}: Model indicated failure to generate. Skipping.")
                    continue
                generated_questions["long_answer"].append({
                    "type": "long_answer",
                    "question": laq_data['question'],
                    "answer_guideline": laq_data['guideline'],
                    "marks": 8
                })
                log_progress(f"Successfully generated and processed Long Answer Question {i+1}.")
            else:
                log_progress(f"Failed to generate valid LAQ {i+1} (data missing or not dict). Received: {str(laq_data)[:300]}...")
        log_progress(f"Finished LAQ generation. Got {len(generated_questions['long_answer'])} LAQs.")

    return generated_questions

# --- Example Usage ---
if __name__ == '__main__':
    dummy_text_long = """
    The Renaissance, a transformative period in European history, spanned roughly from the 14th to the 17th century,
    marking the transition from the Middle Ages to modernity. Originating in Italy, particularly Florence,
    it was characterized by a fervent renewed interest in the classical art, literature, and philosophy of ancient Greece and Rome.
    This 'rebirth' was fueled by several factors, including increased trade which brought wealth and new ideas,
    the fall of Constantinople in 1453 which led to an influx of Greek scholars and texts into Italy,
    and the patronage of wealthy families like the Medici.
    Key figures such as Leonardo da Vinci, Michelangelo, and Raphael produced masterpieces that embodied
    Renaissance ideals of humanism, realism, and individualism. Humanism, a central intellectual movement,
    emphasized human potential and achievements, shifting focus from purely theological concerns.
    The invention of the printing press by Johannes Gutenberg around 1440 played a crucial role in disseminating
    these new ideas across Europe, accelerating intellectual discourse and literacy.
    The Renaissance also saw significant advancements in science, with figures like Copernicus challenging
    geocentric models of the universe, and Vesalius revolutionizing the study of human anatomy.
    However, the period was not without its turmoil, including political instability and religious conflicts
    that would eventually lead to the Reformation.
    """
    
    log_progress(f"--- Starting Question Generation Example ---")
    questions = generate_questions_from_text(
        dummy_text_long, 
        num_mcq=2,
        num_short_answer=2,
        num_long_answer=1,
        subject="History",
        grade_level="University"
    )

    log_progress(f"--- Question Generation Complete. Displaying Results ---")

    print("\n--- Generated MCQs ---")
    if questions["mcq"]:
        for q_idx, q_data in enumerate(questions["mcq"]):
            print(f"\nMCQ {q_idx+1}:")
            print(f"  Q: {q_data['question']}")
            for i, opt in enumerate(q_data['options']):
                print(f"    {chr(65+i)}. {opt} {'(Correct)' if i == q_data['correct_option_index'] else ''}")
            print(f"  Marks: {q_data['marks']}")
    else:
        print("No MCQs generated or all failed.")

    print("\n--- Generated Short Answer Questions ---")
    if questions["short_answer"]:
        for q_idx, q_data in enumerate(questions["short_answer"]):
            print(f"\nShort Answer {q_idx+1}:")
            print(f"  Q: {q_data['question']}")
            print(f"  Guideline: {q_data['answer_guideline']}")
            print(f"  Marks: {q_data['marks']}")
    else:
        print("No Short Answer Questions generated or all failed.")

    print("\n--- Generated Long Answer Questions ---")
    if questions["long_answer"]:
        for q_idx, q_data in enumerate(questions["long_answer"]):
            print(f"\nLong Answer {q_idx+1}:")
            print(f"  Q: {q_data['question']}")
            print(f"  Guideline: {q_data['answer_guideline']}")
            print(f"  Marks: {q_data['marks']}")
    else:
        print("No Long Answer Questions generated or all failed.")

    log_progress("--- Example Script Finished ---")